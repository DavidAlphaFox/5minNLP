#  5分钟NLP-从 0 到 1 构建知识图谱 -以腾讯Topbase为例

[toc]



### 一、知识图谱简介

#### 1.1 定义

知识图谱以结构化的形式描述客观世界中概念、实体及其关系。

结构化知识是以图形式进行表示，图的节点表示语义符号（实体，概念），图的边表示符号之间的语义关系（主题曲-演唱歌曲-父亲-儿子-子类），此外每个实体还有指向非实体级别的边（通常称之为属性），如：人物的出生日期，主要成就等。

![1604560874431](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604560874431.png)

#### 1.2、构建流程



![image-20201108001529479](5%E5%88%86%E9%92%9FNLP-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/image-20201108001529479.png)

#### 1.3 现有知识图谱

DBpedia

Wikidata

复旦大学GDM实验室中文知识图谱CN-DBpedia

中文开放知识图谱联盟

#### 1.4 应用 

##### 商城智能客服

通过构建商品类目-商品信息-评论信息-促销优惠信息-支付信息-物流信息知识图谱，这样一张大的图可以帮助我们对用户所提的问题进行解释回答，某种程度是

![image-20201108003840368](5%E5%88%86%E9%92%9FNLP-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/image-20201108003840368.png)





知识图谱设计：
![image-20201108004031071](5%E5%88%86%E9%92%9FNLP-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/image-20201108004031071.png)



##### 页面搭建

设想是将商品关联关键词，这样通过关键词来在知识图谱中找到关联商品，可实时的根据当前流行的关键词找出商品做落地页，将同类关联的商品聚合起来，放在资源落地页，实时高效。

##### 商品推荐

通过构建买家的搜索、浏览、下单等关系，构建买家-商品两者的知识图谱，从用户出发，向一些用户推荐商品，这其实不仅仅考虑到知识图谱，更考虑如何刻画用户画像，对用户的年纪、经历的事情做一些简单的刻画，毕竟大多数人都要经过“小学 - > 初中 - > 高中 - > 大学 - > 工作租房 - > 买房 - > 结婚 - > 养育小孩”等等阶段，不同阶段的用户需求是不一样的，但别人的需求在未来就可能是你的需求，我们结合这些行为，把需求 - 商品的关系抽象化，在未来就可以重复应用在不用用户身上。

##### 金融行业应用

1、 股票投研情报分析
通过知识图谱相关技术从招股书、年报、公司公告、券商研究报告、新闻等半结构化表格和非结构化文本数据中批量自动抽取公司的股东、子公司、供应商、客户、合作伙伴、竞争对手等信息，构建出公司的知识图谱。在某个宏观经济事件或者企业相关事件发生的时候，券商分析师、交易员、基金公司基金经理等投资研究人员可以通过此图谱做更深层次的分析和更好的投资决策，比如在美国限制向中兴通讯出口的消息发布之后，如果我们有中兴通讯的客户供应商、合作伙伴以及竞争对手的关系图谱，就能在中兴通讯停牌的情况下快速地筛选出受影响的国际国内上市公司从而挖掘投资机会或者进行投资组合风险控制。

2、反欺诈分析
通过融合来自不同数据源的信息构成知识图谱，同时引入领域专家建立业务专家规则。我们通过数据不一致性检测，利用绘制出的知识图谱可以识别潜在的欺诈风险。比如借款人张xx和借款人吴x填写信息为同事，但是两个人填写的公司名却不一样, 以及同一个电话号码属于两个借款人，这些不一致性很可能有欺诈



### 二、topbase 技术体系简介

 TopBase  包括知识图谱体系构建，数据生产流程，以及存储查询系统 。

![1604561072528](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604561072528.png)

### 三、知识体系构建

知识体系的构建是指采用什么样的方式来组织和表达知识 。

**1、定义概念类别体系**  

​       手动定义类别-子类，参考 Schema.org、Dbpedia、大词林、百科（搜狗） 。

​       上下位关系挖掘系统  自动化构建大量的细粒度概念 ， 例如 《不能说的秘密》还具有细粒度的概念：“青春校园爱情电影”，“穿越电影”。 

**2、 其次是定义关系和属性：** 

​       关系用于描述不同实体间的联系，如：夫妻关系（连接两个人物实体），作品关系（连接人物和作品实体）等；

​       属性用于描述实体的内在特征，如人物类实体的出生日期，职业等。  

**3、 定义约束**：定义关系属性的约束信息（属性的定义域，值域）可以保证数据的一致性，避免出现异常值，比如：年龄必须是 Int 类型且唯一（单值），演员作品的值是 String 类型且是多值，出生日期的属性值是 Date 类型。   

### 四、数据生产

数据生产流程是知识图谱构建的核心内容，主要包括下载平台，抽取平台，知识规整模块，知识融合模块，知识推理模块，实体重要度计算等。

#### 4.1 下载平台-实体数据下载

下载平台是知识图谱获取源数据平台，负责及时发现新实体和实体的变化信息并下载



![1604565347847](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604565347847.png) 

针对热门实体信息的更新策略主要有：

**定时遍历重点网站种子页**，从各大站点主页更新，采用广搜的方式层层下载实体页面信息；
**基于新闻正文文本中挖掘新实体，**从新闻语料中更新，然后拼接实体名称生成百科 URL 下载；
**通过挖掘 querylog 中的实体**，从搜索 query log 中更新，然后拼接实体生成百科 URL 下载。基于 querylog 的实体挖掘算法主要是基于实体模板库和 QQSEG-NER 工具；
**知识图谱已有的重要度高的实体**定期重新下载，从知识图谱已有数据中更新，；
**将人工（业务）获得的 URL** 送入下载平台获取实体信息；从人工运营中更新，
**某个热门实体信息变更**，则其相关实体信息也有可能变更，所以需要获得热门实体的相关实体，进行相应更新。

**重要关系属性进行专项更新**。如明星等知名人物的婚姻感情关系我们主要通过事件挖掘的方式及时更新，如：离婚事件会触发已有关系“妻子”“丈夫”变化为“前妻”“前夫”，恋爱事件会触发“男友”“女友”关系等。此外，基于非结构化抽取平台获得的三元组信息也有助于更新实体的关系属性。 

#### 4.2 抽取平台-关系属性抽取

 Topbase 的抽取平台主要包括结构化抽取，非结构化抽取和专项抽取。

##### 4.2.1. 结构化抽取平台

基于 Xpath 解析的抽取平台，  定义好抽取网页的种子页面如：baike.com,然后从网页源码中拷贝 Infobox 中属性的 xpath 路径  

![1604563030359](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604563030359.png)

##### 4.2.2 **非结构化抽取平台** 

![1604563103738](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604563103738.png)

1、首先我们获取知识图谱中重要度高的实体名构建**实体 Tri 树**，

2、**回标新闻数据和百科正文数据**，**并将包含实体的句子作为候选抽取语料**  （新闻和百科数据需要区别对待，新闻数据往往包含最及时和最丰富的三元组信息，百科数据质量高，包含准确的知识，且百科摘要或正文描述相对简单，抽取结果的准确率高） 

3、**将匹配上的实体链接到知识库的已有实体中**，结合 Topbase 的实体链接服务，避免了后期的数据融合。比如：实体“李娜”匹配到一句话是“歌手李娜最终归一了佛门”，那么这句话中的李娜会对应到知识库中的歌手李娜，而不是网球李娜

4、 **抽取服务模块，它是非结构化抽取策略的集合。** 其主要包括离线模型构建部分以及在线服务部分。

![1604563341956](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604563341956.png) 

```
抽取策略**主要可以简单归纳为三大类方法：

**a. 基于规则的抽取模块**：有些属性具有很强的模板（规则）性质，所以可以通过人工简单的配置一些模板规则就可以获得高准确率的三元组结果。例如，地理位置，人物描述 tag 等。

**b.   基于 mention (粗略分类)识别+关系分类模块**：基本思想是先用 NER 或者词典匹配等方式识别出句子中的 mention，然后利用已有的实体信息以及识别出来的 mention 进行属性分类。举例：给定识别出 mention 的句子“<org>腾讯</org>公司是由<per>马化腾</per>创立的。”,用 schema 对输入进行调整，一种情况是 org 作为头实体，per 作为尾实体，那么该样本的分类结果是关系“创始人” 

**c、 基于序列标注模块**：许多属性值是无法进行 mention 识别，因此针对这类属性，采用一种序列标注的联合抽取方式来同时识别实体的属性值以及属性。这类属性主要有人物的“主要成就”信息，人物的描述 tag 信息，以及一些数值型属性信息。 
```

5、 **新三元组结果**会和知识库中已有的三元组数据进行匹配并给每一个抽取得到的三元组结果进行置信度打分，如果知识库已经存在该三元组信息则过滤，如果知识库中三元组和抽取得到的三元组发生冲突则进入众包标注平台，如果三元组是新增的知识则根据他们的分值决定是否可以直接入库或者送入标注平台。此外，标注平台的结果数据会加入到抽取服务中 Fine-tune 模型，不断提升抽取模型的能力。 



##### 4.2.3 专项抽取

专项抽取包括：上位词抽取（概念），实体描述抽取，事件抽取，别名抽取等。

######  **1 ) 上位词抽取**

 上位词可以理解为实体细粒度的概念 ，主要从知识图谱的属性数据，百科人工标注 Tag，纯文本语料3方抽取。 可以进行上位词合并和进一步的进行图谱的连接预测。

![1604564705078](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604564705078.png)



######  **2) 实体描述 tag 抽取** 

 实体描述 tag 是指能够描述实体某个标签的短句 。下图 是从新闻文本数据中挖掘到的实体“李子柒”的部分描述 tag 

![1604564942498](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604564942498.png)

描述 tag 抽取的核心模块以 QA-bert 为主的序列标注模型，query 是给定的实体信息，答案是句子中的描述片段。此外，还包括一系列的预处理过滤模块和后处理规整过滤模块。 

######  **3)事件抽取**

 事件抽取的目的是合并同一事件的新闻数据并从中识别出事件的关键信息生成事件的描述。事件抽取的基本流程如下：

![1604565012744](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604565012744.png)

 按实体分堆   -   提取关键词，聚类  -事件合并 -事件生成

#### 4.3 知识规整-实体定位

 知识规整目的是将实体数据映射到知识体系，实体定位，并对其关系属性等信息进行去噪， 归一化等预处理 。

实体定位挑战： 概念类别多，属性歧义（组合，歌手），简介迷惑性。 例如，左侧是从百科页面获取的武则天人物信息，右侧是从电影相关网站中获得的武则天信息，那么左侧的“武则天”应该被视为“人物类--历史人物--帝王”，右侧“武则天”应该被视为“作品--影视作品--电影”。 

![1604566328557](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604566328557.png)

但是实体定位本质上是个多分类问题，下面称实体分类。

#####  **4.3.1 实体分类的训练样本构建**



![1604566701629](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604566701629.png)

**属性规则模块**：每个实体页面包含了实体结构化属性信息，利用这些属性字段可以对实体进行一个规则的分类。如：人物类别的实体大多包含民族，出生日期，职业等字段，歌手类实体的职业字段中可能有“歌手”的属性值。 

**简介分类模块**：简介分类模块以规则模块的数据作为训练数据，可以得到一个以简介为实体分类依据的分类模型，然后基于该模型预测属性规则模块无法识别的实体，选择高置信度的结果作为训练数据 2。 

 **自动构建的训练数据去噪模块**：基于规则和简介分类模块可以得到部分分类样本，但是这些训练样本不可避免的会引入噪声，所以我们引入 N-折交叉训练预测自清洗数据，进一步保留高置信的训练样本，清洗思路如下图所示。

 ![1604566786565](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604566786565.png)

 **运营模块**：运营模块主要包括日常 badcase 收集以及标注人员审核的预测置信度不高的样本。运营数据会结合自动构建数据，联合训练最终的实体分类模型。 

#####  **4.3.2 实体分类的特征选择**

属性名称：除了通用类的属性名称，如：中文名，别名，正文，简介等，其他属性名称都作为特征； 

属性值：不是所有的属性值都是有助于实体分类，如性别的属性值“男”或者“女”对区分该实体是“商业人物”和“娱乐人物”没有帮助，但是职业的属性值如“歌手”“CEO”等对于实体的细类别则有很强的指示作用，这些属性值可以作为实体细分类的重要特征。一个属性值是否需要加入他的属性值信息，我们基于第一部分得到的训练数据，利用特征选择指标如卡方检验值，信息增益等进行筛选。

 简介：由于简介内容相对较长且信息冗余，并非用得越多越好。针对简介的利用我们主要采用百科简介中头部几句话中的主语是该实体的句子。 

##### 4.3.3 实体分类模型

- 模型架构：基于 bert 预训练语言模型的多 Label 分类模型

![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604567047411.png)图16 实体分类基础模型

- 模型输入：我们针对上述特征进行拼接作为 bert 的输入，利用[sep]隔开实体的两类信息，每一类信息用逗号隔开不同部分。第一类信息是实体名称和实体简介，刻画了实体的一个基本描述内容，第二类信息是实体的各种属性，刻画了实体的属性信息。例如，刘德华的输入形式如下：

  ![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604567047447.png)实体分类模型的输入形式

模型 loss：基于层次 loss 方式，实体 Label 是子类：父类 Label 要转换为正例计算 loss；实体 Label 是父类：所有子类 label 以一定概率 mask 不产生负例 loss，避免训练数据存在的细类别漏召回问题。

#### 4.4 知识融合-不同来源实体对齐

 知识融合的核心是实体对齐，即如何将不同来源的同一个实体进行合并。

```
如从搜狗百科，体育页面以及 QQ 音乐都获取到了"姚明"信息，首先需要判断这些来源的"姚明"是否指同一实体，如果是同一个实体则可以将他们的信息进行融合，如果不是（如QQ 音乐的姚明页面）则不应该将其融合。
```

#####  **挑战**  

不同来源实体的属性信息重叠少，导致相似度特征稀疏，容易欠融合。

 同系列作品（电影，电视剧）相似度高，容易过融合，如第一、第二部还珠格格电视剧 

 多路来源的实体信息量很大（亿级别页面），如果每次进行全局融合计算复杂度高，而且会产生融合实体的 ID 漂移问题。 

##### 技术路径：

![1604567693891](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/1604567693891.png)

###### **1)数据分桶**

数据分桶的目的是对所有的多源实体数据进行一个粗聚类，粗聚类的方法基于简单的规则对数据进行分桶，具体规则主要是同名（原名或者别名相同）实体分在一个桶内，出生年月和出生地一致的人物分在一个桶。

###### **2)实体相似度计算**

实体相似度直接决定了两个实体是否可以合并，它是实体对齐任务中的核心。为了解决相似属性稀疏导致的欠融合问题，我们引入异构网络向量化表示的特征，为了解决同系列作品极其相似的过融合问题，我们引入了互斥特征。

```
异构网络向量化表示特征：每个来源的数据可以构建一个同源实体关联网络，边是两个实体页面之间的超链接，百科空间可以构建一个百科实体关联网络，影视剧网站可以构建一个影视剧网站的实体关联网络。不同空间的两个实体，如果存在高重合度信息，容易判别二者相似度的两个实体，可以建立映射关系（如影视剧网站的梁朝伟页面和百科的梁朝伟页面信息基本一致，则可以认为二者是同一个实体，建立链接关系），这样可以将多源异构网络进行合并，梁朝伟和刘德华属于连接节点，两个无间道重合信息少，则作为两个独立的节点。然后基于 deepwalk 方式得到多源异构网络的节点向量化表示特征。

文本相似特征：主要是针对存在简介信息的实体，利用 bert 编码得到向量，如果两个实体都存在简介信息，则将两个简介向量进行点乘得到他们的文本相似度特征；
基本特征：其他属性的相似度特征，每一维表示属性，每一维的值表示该属性值的一个 Jaccard 相似度；
互斥特征：主要解决同系列作品及其相似的问题，人工设定的重要区分度特征，如电视剧的集数，系列名，上映时间。
```

最后，按照下图结构将上述相似度特征进行融合预测两两实体是否是同一实体；

![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604568040032.png)



1. **知识推理**：由于处理数据的不完备性，上述流程构建的知识图谱会存在知识缺失现象（实体缺失，属性缺失）。知识推理目的是利用已有的知识图谱数据去推理缺失的知识，从而将这些知识补全。此外，由于已获取的数据中可能存在噪声，所以知识推理还可以用于已有知识的噪声检测，净化图谱数据。
2. **实体知名度计算**：最后，我们需要对每一个实体计算一个重要性分数，这样有助于更好的使用图谱数据。比如：名字叫李娜的人物有网球运动员，歌手，作家等，如果用户想通过图谱查询“李娜是谁”那么图谱应该返回最知名的李娜（网球运动员）。

######  **3) 相似实体的聚类合并** 

**Base 融合**：在上述步骤的基础上，我们采用层次聚类算法，对每一个桶的实体进行对齐合并，得到 base 版的融合数据，然后赋予每一个融合后的实体一个固定的 ID 值，这就得到了一个 Base 的融合库；

**增量融合**：对于每日新增的实体页面信息，我们不再重新进行聚类处理，而是采用“贴”的模式，将每一个新增实体页面和已有的融合实体进行相似度计算，判断该实体页面应该归到哪一个融合实体中，如果相似度都低于设置的阈值，则该新增实体独立成一堆，并设置一个新的融合实体 ID。增量融合的策略可以避免每次重复计算全量实体页面的融合过程，方便数据及时更新，同时保证各个融合实体的稳定性，不会轻易发生融合实体 ID 的漂移问题；

**融合拆解**：由于 Base 融合可能存在噪声，所以我们增加了一个融合的修复模块，针对发现的 badcase，对以融合成堆的实体进行拆解重新融合，这样可以局部修复融合错误，方便运营以及批量处理 badcase。



#### 4.5 知识关联

 **知识关联（链接预测）**是将实体的属性值链接到知识库的实体中，构建一条关系边 

例如：“三国演义”的作者属性值是“罗贯中”字符串，知识关联需要将该属性值链接到知识库中的实体“罗贯中”，这样实体“三国演义”和“罗贯中”之间存在一条“作者”的关系边。 

Topbase 的知识关联方案分为基于超链接的关联和基于 embedding 的文本关联两种方式 。

##### 4.5.1 超链接关联

 超链接关联为知识图谱补充了第一批边关系 ，利用网页中存在的超链接对知识图谱中的实体进行关联，如百科“三国演义”页面中，其“作者”属性链接到“罗贯中”的百科页面（如图 24 所示）。

##### 4.5.2 基于 embedding 的文本关联 

 在已知头实体、关系的基础上，在候选集中对尾实体进行筛选，尾实体的候选集是通过别名匹配召回。 如”三国演义“中的“主要人物”属性，我们利用其属性值字符串”曹操“去 Topbase 库里匹配，召回所有和”曹操”同名称的实体作为建立链接关系的候选。然后利用知识库 embedding 的方法从候选实体中选择最相似的实体作为他的链接实体。 

基于知识库embedding 模型结构如下

 **TextEnhanced+TransE embeding 模型**

 ![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604568699551.png)

 ```
链接关系预测是通过模型将实体和关系的属性信息、结构信息嵌入到一个低维向量中去，利用低维向量去对缺失的尾实体进行预测。 
TransE 是将实体与关系映射到同一向量空间下，它是依据已有的边关系结构对实体之间的边关系进行预测，对孤立实体或链接边较少的实体预测效果较差。为了引入文本信息，解决模型对孤立实体预测的难题，模型使用 TextEnhanced 对文本信息进行嵌入。TextEnhanced 通过 NN 模型对文本信息嵌入后，利用 Attention 机制将文本信息嵌入到 Trans 系列的实体向量中，进而对尾实体进行预测。 
 ```

#### 4.6 知识推理

知识关联是在已知属性值的前提下，通过名称匹配的方式得到关联实体的候选集，所以知识关联无法补充缺失属性值的链接关系。  如上图中“三国演义”的信息中并没有“关羽”，**知识推理**目的是希望能够挖掘“三国演义”和“关羽”的潜在关系。 

topbase 以规则推理为主 

#####  **4.6.1 伴随推理**

在已经被链接的两个实体之间，根据两个实体的属性信息，发现两者间蕴含的其它关系。例如实体 A 已经通过“配偶”关系与实体 B 相连，实体 A 的性别为“男”，实体 B 的性别为“女”，则伴随推理会生成一条“妻子”关系边，将实体 A 与实体 B 链接在一起，代表 B 为 A 的妻子。

```
伴随推理的规则可以通过统计同时关联起两个实体的属性共现比例得到。
```

 ![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604569464117.png) Topbase的伴随推理规则库示列 

##### **4.6.2 反向推理**

是依据边之间的互反关系，为已经链接的两个实体再添加一条边。比如实体 A 通过“作者”边与实体 B 相连，代表实体 B 是实体 A 的作者，则可以直接生成一条从实体 B 指向实体 A 的“作品”边， 

 ![img](%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/640-1604569479769.png)Topbase的反向关联规则库示列 

#####  **4.6.3 多实体推理**

在多个实体之间挖掘蕴含的边关系，是一种更复杂的关联规则，如第一种形式：A 的父亲是 B，B 的母亲是 C，则 A 的奶奶是 C，该形式通过统计 A+PATH = C，A+R0=C，情况得到规则  [PATH(R1R2)=R0]；第二种形式是 A 的母亲是 B，A 的儿子 C，则 B 的孙子是 C，该形式通过统计：A+R1 = B，A+R2=C，B+R0=C 的情况，得到规则[R1 &R2 = R0]。 

#### 4.7 实体知名度计算（Popularity）

 实体的知名度（Popularity）指标可以用于量化不同实体的重要性程度，方便我们更好的使用图谱数据.

#####  4.7.1 Topbase 知识库的 popularity 计算流程 

1、抽取实体页面之间的超链接关系，以此为基础通过修改后的 pagerank 算法来计算所有实体的 popularity；

2、对于难以通过 pagerank 算法计算的新热实体的 popularity，再进行规则干预。

3、对于仍然难以解决的 case，则直接对其 popularity 值进行人工赋值。 

#####  4.7.2 多类型边关系的 pagerank 算法 

基础：一个实体 A 对另一个实体 B 的引用（链接），表示实体 A 对于实体 B 的认可，链接到 B 的实体越多，表示 B 受到的认可越多.

改进：实体之间可以有多条边，且有多种类型的边 ,  链接关系之间也有可信度的差别，只是在进行分布概率的流转时有所区别。

 **新热实体的 Popularity 调整** 

发现新热实体的，然后对发现的新热实体的 popularity 进行调整，使其 popularity 值在同名实体中处于最高的位置。

新热实体的发现目前基于两类方法：

1、发现的热门实体可以直接对应到知识库中的某个实体， 从 Topbase 监控的重点网站页面中直接获取最近热门的实体。 

2、  先发现一些热门的实体名，包括：一、从微博热搜榜中爬取热门话题，通过命名实体识别方法识别其中的人名和机构名，将其作为热门实体名；二、将新闻中每天曝光的高频次标签作为实体名。 



### 五、知识库的存储和查询

#### 5.1 存储知识图谱的工具

主要分为两类：第一类是RDF存储系统，另一类是图数据库。

- RDF一个重要的设计原则是数据的易发布以及共享，其次，RDF以三元组的方式来存储数据而且不包含属性信息。主要有：jena, rdf4j ,redland ， magiclogic 

  RDF序列化的方式主要有：RDF/XML，N-Triples，Turtle，RDFa，JSON-LD.

  例如：rdf/XML 

  ```
  <?xml version="1.0"?>
  
  <rdf:RDF
  xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"   ##  rdf 是命名空间的简称
  xmlns:cd="http://www.recshop.fake/cd#">                           ##  cd  也是简称，属性的简称
  
  <rdf:Description
   rdf:about="http://www.recshop.fake/cd/Empire Burlesque">  ## 直接用rdf来表示
    <cd:artist>Bob Dylan</cd:artist>
    <cd:country>USA</cd:country>
    <cd:company>Columbia</cd:company>
    <cd:price>10.90</cd:price>
    <cd:year>1985</cd:year>
  </rdf:Description>
  
  <rdf:Description
   rdf:about="http://www.recshop.fake/cd/Hide your heart">
    <cd:artist>Bonnie Tyler</cd:artist>
    <cd:country>UK</cd:country>
    <cd:company>CBS Records</cd:company>
    <cd:price>9.90</cd:price>
    <cd:year>1988</cd:year>
  </rdf:Description>
  .
  .
  .
  </rdf:RDF>
  ```

  ```
  turtle 存储格式：
  @prefix person: <http://www.kg.com/person/> .    # 加@prefix  利用person 代替后面网址命名空间
  @prefix place: <http://www.kg.com/place/> .
  @prefix : <http://www.kg.com/ontology/> .            # 这个还不清楚是干什么的
  
  person:1 :chineseName "罗纳尔多·路易斯·纳萨里奥·德·利马"^^string.
  person:1 :career "足球运动员"^^string.
  person:1 :fullName "Ronaldo Luís Nazário de Lima"^^string.
  person:1 :birthDate "1976-09-18"^^date.
  person:1 :height "180"^^int. 
  person:1 :weight "98"^^int.
  person:1 :nationality "巴西"^^string. 
  person:1 :hasBirthPlace place:10086.
  place:10086 :address "里约热内卢"^^string.
  place:10086 :coordinate "-22.908333, -43.196389"^^string.
  
  ```

  

- 图数据库则把重点放在了高效的图查询和搜索上。图数据库一般以属性图为基本的表示形式，所以实体和关系可以包含属性，这就意味着更容易表达现实的业务场景。主要工具有：neo4j, cosmos DB,arangodb,

  ![image-20201108001946279](5%E5%88%86%E9%92%9FNLP-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/image-20201108001946279.png)



#### 5.2topbase的存储查询方案

 JanusGraph  开源，超大图， 超大规模并发事务和可操作图运算  

查询语句： Gremlin

复杂查询：  Es 构建复杂查询的数据索引   

图数据库存储服务 ：  ScyllaDb 

Graph_Loader  ： 转换为JanusGraph  格式



- 



 